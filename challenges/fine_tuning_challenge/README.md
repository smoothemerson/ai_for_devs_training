# Fine-tuning Challenge - ClassificaÃ§Ã£o de Mensagens

Este projeto foi desenvolvido para satisfazer o **Desafio Fine-tuning** da Rocketseat, que consiste em treinar um modelo de linguagem para classificar automaticamente mensagens de clientes de uma rede varejista.

## ğŸ“‹ Objetivo

Realizar o fine-tuning de um modelo BERT para classificar mensagens de clientes em duas categorias:

- **"venda"**: Mensagens relacionadas Ã  intenÃ§Ã£o de compra de produtos
- **"suporte"**: Mensagens relacionadas a dÃºvidas ou problemas com produtos

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.13+**
- **Transformers** (Hugging Face)
- **BERT** (bert-base-uncased)
- **Datasets** para carregamento dos dados
- **Evaluate** para mÃ©tricas de avaliaÃ§Ã£o
- **PyTorch** como backend

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ train.jsonl  # Dados de treinamento
â”‚   â””â”€â”€ test.jsonl   # Dados de teste
â”œâ”€â”€ main.py          # Script principal de treinamento
â””â”€â”€ README.md        # Este arquivo
```

## ğŸš€ Como Executar

1. Instale as dependÃªncias:
```bash
uv sync
```

2. Execute o script de treinamento:
```bash
python main.py
```

3. O modelo treinado serÃ¡ salvo no diretÃ³rio `bert-hate-speech-test/`

## ğŸ“Š Datasets

Os datasets utilizados sÃ£o arquivos JSONL com o formato:
```json
{"prompt": "OlÃ¡, gostaria de fazer a aquisiÃ§Ã£o do novo produto", "completion": "venda"}
{"prompt": "tudo bom, queria verificar como funciona a TV Smart x0912", "completion": "suporte"}
```

**Nota:** Os dados foram gerados sinteticamente para fins didÃ¡ticos.

## ğŸ¯ Resultados

O modelo foi treinado por 3 Ã©pocas e avaliado usando a mÃ©trica de acurÃ¡cia. Os melhores checkpoints foram salvos automaticamente durante o treinamento.

### MÃ©tricas de Treinamento
- **Training Loss**: 0.0565
- **Training Runtime**: 37.66s
- **Training Samples/Second**: 39.83
- **Ã‰pocas Completadas**: 3.0

### MÃ©tricas de AvaliaÃ§Ã£o
- **Eval Loss**: 0.0006
- **Eval Accuracy**: 100.00% (1.0000)
- **Eval Runtime**: 0.12s
- **Eval Samples/Second**: 837.07

O modelo alcanÃ§ou **100% de acurÃ¡cia** no conjunto de teste, demonstrando excelente capacidade de classificar mensagens entre "venda" e "suporte".

---

**Desenvolvido como parte do desafio de Fine-tuning da Rocketseat**