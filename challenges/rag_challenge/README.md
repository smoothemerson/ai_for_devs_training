# Desafio RAG - Os SertÃµes

## ğŸ“– DescriÃ§Ã£o

Este projeto implementa trÃªs diferentes estruturas de **RecuperaÃ§Ã£o e GeraÃ§Ã£o de Respostas (RAG)** para responder questÃµes sobre o livro **"Os SertÃµes"** de Euclides da Cunha. O sistema utiliza modelos de linguagem local (Ollama) e diferentes estratÃ©gias de recuperaÃ§Ã£o de informaÃ§Ãµes para fornecer respostas precisas e contextualizadas.

## ğŸ—ï¸ Arquitetura

O projeto implementa trÃªs abordagens distintas de RAG:

### 1. Naive RAG
- **EstratÃ©gia**: DivisÃ£o simples do documento em chunks de tamanho fixo
- **Chunk Size**: 4000 caracteres com overlap de 20
- **RecuperaÃ§Ã£o**: Top-3 documentos mais similares
- **CaracterÃ­sticas**: Abordagem direta e rÃ¡pida

### 2. Parent RAG
- **EstratÃ©gia**: Hierarquia de documentos (pais e filhos)
- **Child Chunks**: 500 caracteres (overlap 50) para busca
- **Parent Chunks**: 4000 caracteres (overlap 200) para contexto
- **Vantagem**: Busca granular com contexto amplo

### 3. Rerank RAG
- **EstratÃ©gia**: Re-ranqueamento com Cohere Rerank v3.5
- **RecuperaÃ§Ã£o Inicial**: Top-10 documentos
- **Re-ranking**: Reduz para top-3 mais relevantes
- **Vantagem**: Maior precisÃ£o na seleÃ§Ã£o de contexto

## ğŸš€ Tecnologias Utilizadas

- **Python 3.13+**
- **FastAPI** - API REST para endpoints
- **LangChain** - Framework para LLM e RAG
- **Ollama** - Servidor de modelos local
- **ChromaDB** - Banco de dados vetorial
- **Cohere** - ServiÃ§o de re-ranking
- **Docker** - ContainerizaÃ§Ã£o
- **UV** - Gerenciamento de dependÃªncias

### Modelos Utilizados

- **LLM**: `llama3.2:3b` (Ollama)
- **Embeddings**: `nomic-embed-text:v1.5` (Ollama)
- **Rerank**: `rerank-v3.5` (Cohere)

## ğŸ“‹ PrÃ©-requisitos

- Python 3.13+
- Docker e Docker Compose
- UV (gerenciador de pacotes)
- NVIDIA GPU (recomendado para Ollama)
- Chave API do Cohere

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/smoothemerson/ai_for_devs_training.git
cd challenges/rag_challenge
```

### 2. Configure as variÃ¡veis de ambiente
```bash
cp .env.example .env
# Edite o arquivo .env e adicione sua COHERE_API_KEY
```

### 3. Instale as dependÃªncias
```bash
uv sync
```

### 4. Adicione o documento
Coloque o PDF do livro "Os SertÃµes" na pasta `document/` com o nome `sertoes_livro_euclides`.

### 5. Execute com Docker
```bash
# Inicie os serviÃ§os
docker-compose up -d
```

### 6. ExecuÃ§Ã£o local (alternativa)
```bash
# Certifique-se que o Ollama esteja rodando
ollama serve

# Baixe os modelos necessÃ¡rios
ollama pull llama3.2:3b
ollama pull nomic-embed-text:v1.5

# Execute a aplicaÃ§Ã£o
uv run python -m src.main
```

## ğŸ”§ Uso da API

### Endpoints DisponÃ­veis

- **GET** `/` - Redireciona para documentaÃ§Ã£o
- **GET** `/healthcheck` - VerificaÃ§Ã£o de saÃºde
- **POST** `/chat/naive_rag` - Chat com Naive RAG
- **POST** `/chat/parent_rag` - Chat com Parent RAG  
- **POST** `/chat/rerank_rag` - Chat com Rerank RAG

## ğŸ§ª Testes e AvaliaÃ§Ã£o

### Script de Teste AutomÃ¡tico

Execute o script `questions.py` para testar todas as abordagens RAG:

```bash
uv run python questions.py
```

Este script:
- Faz requisiÃ§Ãµes para todos os endpoints RAG
- Testa todas as 5 questÃµes de avaliaÃ§Ã£o
- Salva os resultados na pasta `results/`
- Mede o tempo total de execuÃ§Ã£o

### Resultados

Os resultados sÃ£o salvos em:
- `results/naive_rag.txt`
- `results/parent_rag.txt`
- `results/rerank_rag.txt`

## ğŸ‘¨â€ğŸ’» Autor

**Emerson Rocha**
- Email: emersonfaria019@gmail.com

## ğŸ“š ReferÃªncias

- [Os SertÃµes - Euclides da Cunha (PDF)](https://fundar.org.br/wp-content/uploads/2021/06/os-sertoes.pdf)
- [LangChain Documentation](https://docs.langchain.com/oss/python/langchain/overview)
- [Ollama](https://ollama.com)
- [Cohere Rerank](https://cohere.com)
